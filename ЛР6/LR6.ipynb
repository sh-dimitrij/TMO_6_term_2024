{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "import math\n",
    "from enum import Enum\n",
    "import os\n",
    "# from plotly.express import line\n",
    "#import data\n",
    "#import plotly.express as px\n",
    "# %matplotlib inline \n",
    "sns.set(style=\"ticks\")\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_columns',24)\n",
    "pd.set_option('display.max_colwidth',None)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Suburb         13580 non-null  object \n",
      " 1   Address        13580 non-null  object \n",
      " 2   Rooms          13580 non-null  int64  \n",
      " 3   Type           13580 non-null  object \n",
      " 4   Price          13580 non-null  float64\n",
      " 5   Method         13580 non-null  object \n",
      " 6   SellerG        13580 non-null  object \n",
      " 7   Date           13580 non-null  object \n",
      " 8   Distance       13580 non-null  float64\n",
      " 9   Postcode       13580 non-null  float64\n",
      " 10  Bedroom2       13580 non-null  float64\n",
      " 11  Bathroom       13580 non-null  float64\n",
      " 12  Car            13518 non-null  float64\n",
      " 13  Landsize       13580 non-null  float64\n",
      " 14  BuildingArea   7130 non-null   float64\n",
      " 15  YearBuilt      8205 non-null   float64\n",
      " 16  CouncilArea    12211 non-null  object \n",
      " 17  Lattitude      13580 non-null  float64\n",
      " 18  Longtitude     13580 non-null  float64\n",
      " 19  Regionname     13580 non-null  object \n",
      " 20  Propertycount  13580 non-null  float64\n",
      "dtypes: float64(12), int64(1), object(8)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "encoding = 'windows-1250'\n",
    "data=pd.read_csv(r'C:\\Users\\Dima\\Desktop\\Homework\\3 курс\\ТМО\\ЛР6\\melb_data.csv', encoding = encoding)\n",
    "data.shape\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Price</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13580.0000</td>\n",
       "      <td>13580.0000</td>\n",
       "      <td>13580.0000</td>\n",
       "      <td>13580.0000</td>\n",
       "      <td>13580.0000</td>\n",
       "      <td>13580.0000</td>\n",
       "      <td>13518.0000</td>\n",
       "      <td>13580.0000</td>\n",
       "      <td>7130.0000</td>\n",
       "      <td>8205.0000</td>\n",
       "      <td>13580.0000</td>\n",
       "      <td>13580.0000</td>\n",
       "      <td>13580.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.9380</td>\n",
       "      <td>1075684.0795</td>\n",
       "      <td>10.1378</td>\n",
       "      <td>3105.3019</td>\n",
       "      <td>2.9147</td>\n",
       "      <td>1.5342</td>\n",
       "      <td>1.6101</td>\n",
       "      <td>558.4161</td>\n",
       "      <td>151.9676</td>\n",
       "      <td>1964.6842</td>\n",
       "      <td>-37.8092</td>\n",
       "      <td>144.9952</td>\n",
       "      <td>7454.4174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.9557</td>\n",
       "      <td>639310.7243</td>\n",
       "      <td>5.8687</td>\n",
       "      <td>90.6770</td>\n",
       "      <td>0.9659</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.9626</td>\n",
       "      <td>3990.6692</td>\n",
       "      <td>541.0145</td>\n",
       "      <td>37.2738</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>4378.5818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>85000.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3000.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1196.0000</td>\n",
       "      <td>-38.1825</td>\n",
       "      <td>144.4318</td>\n",
       "      <td>249.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>650000.0000</td>\n",
       "      <td>6.1000</td>\n",
       "      <td>3044.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>177.0000</td>\n",
       "      <td>93.0000</td>\n",
       "      <td>1940.0000</td>\n",
       "      <td>-37.8568</td>\n",
       "      <td>144.9296</td>\n",
       "      <td>4380.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.0000</td>\n",
       "      <td>903000.0000</td>\n",
       "      <td>9.2000</td>\n",
       "      <td>3084.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>440.0000</td>\n",
       "      <td>126.0000</td>\n",
       "      <td>1970.0000</td>\n",
       "      <td>-37.8024</td>\n",
       "      <td>145.0001</td>\n",
       "      <td>6555.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.0000</td>\n",
       "      <td>1330000.0000</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3148.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>651.0000</td>\n",
       "      <td>174.0000</td>\n",
       "      <td>1999.0000</td>\n",
       "      <td>-37.7564</td>\n",
       "      <td>145.0583</td>\n",
       "      <td>10331.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>9000000.0000</td>\n",
       "      <td>48.1000</td>\n",
       "      <td>3977.0000</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>433014.0000</td>\n",
       "      <td>44515.0000</td>\n",
       "      <td>2018.0000</td>\n",
       "      <td>-37.4085</td>\n",
       "      <td>145.5264</td>\n",
       "      <td>21650.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Rooms        Price   Distance   Postcode   Bedroom2   Bathroom  \\\n",
       "count 13580.0000   13580.0000 13580.0000 13580.0000 13580.0000 13580.0000   \n",
       "mean      2.9380 1075684.0795    10.1378  3105.3019     2.9147     1.5342   \n",
       "std       0.9557  639310.7243     5.8687    90.6770     0.9659     0.6917   \n",
       "min       1.0000   85000.0000     0.0000  3000.0000     0.0000     0.0000   \n",
       "25%       2.0000  650000.0000     6.1000  3044.0000     2.0000     1.0000   \n",
       "50%       3.0000  903000.0000     9.2000  3084.0000     3.0000     1.0000   \n",
       "75%       3.0000 1330000.0000    13.0000  3148.0000     3.0000     2.0000   \n",
       "max      10.0000 9000000.0000    48.1000  3977.0000    20.0000     8.0000   \n",
       "\n",
       "             Car    Landsize  BuildingArea  YearBuilt  Lattitude  Longtitude  \\\n",
       "count 13518.0000  13580.0000     7130.0000  8205.0000 13580.0000  13580.0000   \n",
       "mean      1.6101    558.4161      151.9676  1964.6842   -37.8092    144.9952   \n",
       "std       0.9626   3990.6692      541.0145    37.2738     0.0793      0.1039   \n",
       "min       0.0000      0.0000        0.0000  1196.0000   -38.1825    144.4318   \n",
       "25%       1.0000    177.0000       93.0000  1940.0000   -37.8568    144.9296   \n",
       "50%       2.0000    440.0000      126.0000  1970.0000   -37.8024    145.0001   \n",
       "75%       2.0000    651.0000      174.0000  1999.0000   -37.7564    145.0583   \n",
       "max      10.0000 433014.0000    44515.0000  2018.0000   -37.4085    145.5264   \n",
       "\n",
       "       Propertycount  \n",
       "count     13580.0000  \n",
       "mean       7454.4174  \n",
       "std        4378.5818  \n",
       "min         249.0000  \n",
       "25%        4380.0000  \n",
       "50%        6555.0000  \n",
       "75%       10331.0000  \n",
       "max       21650.0000  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb            object\n",
       "Address           object\n",
       "Rooms              int64\n",
       "Type              object\n",
       "Price            float64\n",
       "Method            object\n",
       "SellerG           object\n",
       "Date              object\n",
       "Distance         float64\n",
       "Postcode         float64\n",
       "Bedroom2         float64\n",
       "Bathroom         float64\n",
       "Car              float64\n",
       "Landsize         float64\n",
       "BuildingArea     float64\n",
       "YearBuilt        float64\n",
       "CouncilArea       object\n",
       "Lattitude        float64\n",
       "Longtitude       float64\n",
       "Regionname        object\n",
       "Propertycount    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns='Suburb')\n",
    "data = data.drop(columns='Address')\n",
    "data = data.drop(columns='Type')\n",
    "data = data.drop(columns='Method')\n",
    "data = data.drop(columns='SellerG')\n",
    "data = data.drop(columns='Date')\n",
    "data = data.drop(columns='CouncilArea')\n",
    "data = data.drop(columns='Regionname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb              0\n",
       "Address             0\n",
       "Rooms               0\n",
       "Type                0\n",
       "Price               0\n",
       "Method             92\n",
       "SellerG             0\n",
       "Date                0\n",
       "Distance            0\n",
       "Postcode            0\n",
       "Bedroom2            0\n",
       "Bathroom            0\n",
       "Car                62\n",
       "Landsize            0\n",
       "BuildingArea     6450\n",
       "YearBuilt        5375\n",
       "CouncilArea      1369\n",
       "Lattitude           0\n",
       "Longtitude          0\n",
       "Regionname          0\n",
       "Propertycount       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_columns = data.columns[data.isnull().any()]\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Method', 'Car', 'BuildingArea', 'YearBuilt', 'CouncilArea'], dtype='object')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление строк с пропущенными значениями в столбцах \"Method\" и \"Car\"\n",
    "# data.dropna(subset=[\"Method\", \"Car\"], inplace=True)\n",
    "data.dropna(subset=[\"Car\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполнение пропущенных значений в столбцах \"BuildingArea\", \"YearBuilt\" и \"CouncilArea\"\n",
    "# Для числовых столбцов можно использовать медиану\n",
    "median_BuildingArea = data[\"BuildingArea\"].median()\n",
    "median_YearBuilt = data[\"YearBuilt\"].median()\n",
    "# Для категориального столбца можно использовать наиболее часто встречающееся значение\n",
    "# mode_CouncilArea = data[\"CouncilArea\"].mode()[0]\n",
    "\n",
    "data[\"BuildingArea\"].fillna(median_BuildingArea, inplace=True)\n",
    "data[\"YearBuilt\"].fillna(median_YearBuilt, inplace=True)\n",
    "# data[\"CouncilArea\"].fillna(mode_CouncilArea, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heamy.estimator import Regressor, Classifier\n",
    "from heamy.pipeline import ModelsPipeline\n",
    "from heamy.dataset import Dataset\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление строк с пропущенными значениями в столбцах \"Method\" и \"Car\"\n",
    "# data.dropna(subset=[\"Method\", \"Car\"], inplace=True)\n",
    "data.dropna(subset=[\"Car\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполнение пропущенных значений в столбцах \"BuildingArea\", \"YearBuilt\" и \"CouncilArea\"\n",
    "# Для числовых столбцов можно использовать медиану\n",
    "median_BuildingArea = data[\"BuildingArea\"].median()\n",
    "median_YearBuilt = data[\"YearBuilt\"].median()\n",
    "# Для категориального столбца можно использовать наиболее часто встречающееся значение\n",
    "# mode_CouncilArea = data[\"CouncilArea\"].mode()[0]\n",
    "\n",
    "data[\"BuildingArea\"].fillna(median_BuildingArea, inplace=True)\n",
    "data[\"YearBuilt\"].fillna(median_YearBuilt, inplace=True)\n",
    "# data[\"CouncilArea\"].fillna(mode_CouncilArea, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Применяем One-Hot Encoding к категориальным признакам\n",
    "# data_encoded = pd.get_dummies(data)\n",
    "\n",
    "# # Показываем первые несколько строк преобразованных данных\n",
    "# print(data_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# # Применяем One-Hot Encoding ко всем категориальным признакам\n",
    "# categorical_columns = ['Suburb', 'Type', 'Method', 'SellerG', 'CouncilArea', 'Regionname']\n",
    "# one_hot_encoder = OneHotEncoder()\n",
    "# X_encoded = one_hot_encoder.fit_transform(data[categorical_columns])\n",
    "\n",
    "# # Создаем DataFrame из закодированных признаков\n",
    "# X_encoded_df = pd.DataFrame(X_encoded.toarray(), columns=one_hot_encoder.get_feature_names_out(categorical_columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_encoded, X_test_encoded, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "# print(\"Размер обучающей выборки:\", X_train_encoded.shape[0])\n",
    "# print(\"Размер тестовой выборки:\", X_test_encoded.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: 10864\n",
      "Размер тестовой выборки: 2716\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = data.drop(columns=[\"Price\"])  # Признаки (все столбцы кроме \"Price\")\n",
    "y = data[\"Price\"]  # Целевая переменная (столбец \"Price\")\n",
    "\n",
    "# Разделение выборки на обучающую и тестовую\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Вывод размеров обучающей и тестовой выборок\n",
    "print(\"Размер обучающей выборки:\", X_train.shape[0])\n",
    "print(\"Размер тестовой выборки:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_mae(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    result = mean_absolute_error(y_test, y_pred)\n",
    "    print(model)\n",
    "    print('MAE={}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "MAE=293937.98172785895\n",
      "==========================\n",
      "\n",
      "DecisionTreeRegressor()\n",
      "MAE=227262.7209131075\n",
      "==========================\n",
      "\n",
      "RandomForestRegressor(n_estimators=50)\n",
      "MAE=172045.3649445964\n",
      "==========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Точность на отдельных моделях\n",
    "for model in [\n",
    "    LinearRegression(),\n",
    "    DecisionTreeRegressor(),\n",
    "    RandomForestRegressor(n_estimators=50)\n",
    "]:\n",
    "    val_mae(model)\n",
    "    print('==========================')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем библиотеку heamy\n",
    "# набор данных\n",
    "dataset = Dataset(X_train, y_train, X_test)\n",
    "\n",
    "# модели первого уровня\n",
    "model_tree = Regressor(dataset=dataset, estimator=DecisionTreeRegressor, name='tree')\n",
    "model_lr = Regressor(dataset=dataset, estimator=LinearRegression, parameters={'normalize': True},name='lr')\n",
    "model_rf = Regressor(dataset=dataset, estimator=RandomForestRegressor, parameters={'n_estimators': 50},name='rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "StackingRegressor.__init__() got an unexpected keyword argument 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[230], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m meta_model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Построение стекинга\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m stacking_regressor \u001b[38;5;241m=\u001b[39m \u001b[43mStackingRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_rf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_regressor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Обучение модели\u001b[39;00m\n\u001b[0;32m     12\u001b[0m stacking_regressor\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mTypeError\u001b[0m: StackingRegressor.__init__() got an unexpected keyword argument 'models'"
     ]
    }
   ],
   "source": [
    "# Определите базовые модели\n",
    "model_tree = DecisionTreeRegressor()\n",
    "model_rf = RandomForestRegressor()\n",
    "\n",
    "# Определите мета-модель\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# Построение стекинга\n",
    "stacking_regressor = StackingRegressor(models=[model_tree, model_rf], meta_regressor=meta_model)\n",
    "\n",
    "# Обучение модели\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание на тестовом наборе\n",
    "y_pred = stacking_regressor.predict(X_test)\n",
    "\n",
    "# Оценка качества модели\n",
    "mse = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeCV, LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier, StackingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from joblib import Parallel, delayed\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stacking:\n",
    "    def __init__(self, estimators, final_estimator, blending=False, cv=5, n_jobs=-1):\n",
    "        self.estimators = estimators\n",
    "        self.final_estimator = final_estimator\n",
    "        self.blending = blending\n",
    "        self.cv = cv\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def _X_pred(self, estimator, data):\n",
    "        if self.blending:\n",
    "            X_train_v, y_train_v, X_val = data\n",
    "            return estimator.fit(X_train_v, y_train_v).predict(X_val)\n",
    "        else:\n",
    "            X_train, y_train = data\n",
    "            return cross_val_predict(estimator, X_train, y_train, cv=self.cv)\n",
    "\n",
    "    def _X_test_pred(self, estimator, data):\n",
    "        X_train, y_train, X_test = data\n",
    "\n",
    "        return estimator.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "    def _meta_data(self, X_train, y_train, X_test):\n",
    "        if self.blending:\n",
    "            #used hold-out cross-validation\n",
    "            X_train_v, X_val, y_train_v, y_val = train_test_split(X_train, y_train, random_state=0)\n",
    "            train_data = [X_train_v, y_train_v, X_val]\n",
    "            test_data = [X_train_v, y_train_v, X_test]\n",
    "            meta_y_train = y_val\n",
    "        else:\n",
    "            train_data = [X_train, y_train]\n",
    "            test_data = [X_train, y_train, X_test]\n",
    "            meta_y_train = y_train\n",
    "\n",
    "        cv_X_train_preds = (delayed(self._X_pred)(est, train_data) for est in self.estimators)\n",
    "        X_test_preds = (delayed(self._X_test_pred)(est, test_data) for est in self.estimators)\n",
    "\n",
    "        meta_X_train = pd.DataFrame(Parallel(n_jobs=self.n_jobs)(cv_X_train_preds))\n",
    "        meta_X_test = pd.DataFrame(Parallel(n_jobs=self.n_jobs)(X_test_preds))\n",
    "\n",
    "        return meta_X_train.T, meta_y_train, meta_X_test.T\n",
    "\n",
    "    def fit_predict(self, X_train, y_train, X_test):\n",
    "        # meta learner or blender\n",
    "        meta_X_train, meta_y_train, meta_X_test = self._meta_data(X_train, y_train, X_test)\n",
    "\n",
    "        return self.final_estimator.fit(meta_X_train, meta_y_train).predict(meta_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_boundary_plot(X, y, X_train, y_train, clf, feature_indexes, title=None):\n",
    "    feature1_name, feature2_name = X.columns[feature_indexes]\n",
    "    X_feature_columns = X.values[:, feature_indexes]\n",
    "    X_train_feature_columns = X_train.values[:, feature_indexes]\n",
    "    clf.fit(X_train_feature_columns, y_train.values)\n",
    "\n",
    "    plot_decision_regions(X=X_feature_columns, y=y.values, clf=clf)\n",
    "    plt.xlabel(feature1_name)\n",
    "    plt.ylabel(feature2_name)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Suburb           Address  Rooms   Type        Price      Method  \\\n",
      "0         Abbotsford      85 Turner St      2  house 1480000.0000        sold   \n",
      "1         Abbotsford   25 Bloomburg St      2  house 1035000.0000        sold   \n",
      "2         Abbotsford      5 Charles St      3  house 1465000.0000  sold prior   \n",
      "3         Abbotsford  40 Federation La      3  house  850000.0000   passed in   \n",
      "4         Abbotsford       55a Park St      4  house 1600000.0000  vendor bid   \n",
      "...              ...               ...    ...    ...          ...         ...   \n",
      "13575  Wheelers Hill      12 Strada Cr      4  house 1245000.0000        sold   \n",
      "13576   Williamstown     77 Merrett Dr      3  house 1031000.0000  sold prior   \n",
      "13577   Williamstown       83 Power St      3  house 1170000.0000        sold   \n",
      "13578   Williamstown      96 Verdon St      4  house 2500000.0000   passed in   \n",
      "13579     Yarraville        6 Agnes St      4  house 1285000.0000  sold prior   \n",
      "\n",
      "        SellerG        Date  Distance  Postcode  Bedroom2  Bathroom    Car  \\\n",
      "0        Biggin   3/12/2016    2.5000 3067.0000    2.0000    1.0000 1.0000   \n",
      "1        Biggin   4/02/2016    2.5000 3067.0000    2.0000    1.0000 0.0000   \n",
      "2        Biggin   4/03/2017    2.5000 3067.0000    3.0000    2.0000 0.0000   \n",
      "3        Biggin   4/03/2017    2.5000 3067.0000    3.0000    2.0000 1.0000   \n",
      "4        Nelson   4/06/2016    2.5000 3067.0000    3.0000    1.0000 2.0000   \n",
      "...         ...         ...       ...       ...       ...       ...    ...   \n",
      "13575     Barry  26/08/2017   16.7000 3150.0000    4.0000    2.0000 2.0000   \n",
      "13576  Williams  26/08/2017    6.8000 3016.0000    3.0000    2.0000 2.0000   \n",
      "13577     Raine  26/08/2017    6.8000 3016.0000    3.0000    2.0000 4.0000   \n",
      "13578   Sweeney  26/08/2017    6.8000 3016.0000    4.0000    1.0000 5.0000   \n",
      "13579   Village  26/08/2017    6.3000 3013.0000    4.0000    1.0000 1.0000   \n",
      "\n",
      "       Landsize  BuildingArea  YearBuilt CouncilArea  Lattitude  Longtitude  \\\n",
      "0      202.0000      126.0000  1970.0000       Yarra   -37.7996    144.9984   \n",
      "1      156.0000       79.0000  1900.0000       Yarra   -37.8079    144.9934   \n",
      "2      134.0000      150.0000  1900.0000       Yarra   -37.8093    144.9944   \n",
      "3       94.0000      126.0000  1970.0000       Yarra   -37.7969    144.9969   \n",
      "4      120.0000      142.0000  2014.0000       Yarra   -37.8072    144.9941   \n",
      "...         ...           ...        ...         ...        ...         ...   \n",
      "13575  652.0000      126.0000  1981.0000    Moreland   -37.9056    145.1676   \n",
      "13576  333.0000      133.0000  1995.0000    Moreland   -37.8593    144.8790   \n",
      "13577  436.0000      126.0000  1997.0000    Moreland   -37.8527    144.8874   \n",
      "13578  866.0000      157.0000  1920.0000    Moreland   -37.8591    144.8930   \n",
      "13579  362.0000      112.0000  1920.0000    Moreland   -37.8119    144.8845   \n",
      "\n",
      "                       Regionname  Propertycount  \n",
      "0           Northern Metropolitan      4019.0000  \n",
      "1           Northern Metropolitan      4019.0000  \n",
      "2           Northern Metropolitan      4019.0000  \n",
      "3           Northern Metropolitan      4019.0000  \n",
      "4           Northern Metropolitan      4019.0000  \n",
      "...                           ...            ...  \n",
      "13575  South-Eastern Metropolitan      7392.0000  \n",
      "13576        Western Metropolitan      6380.0000  \n",
      "13577        Western Metropolitan      6380.0000  \n",
      "13578        Western Metropolitan      6380.0000  \n",
      "13579        Western Metropolitan      6543.0000  \n",
      "\n",
      "[13427 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "X1, y1 = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "y1 = pd.Series(LabelEncoder().fit_transform(y1))\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, random_state=0)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age     sex     bmi      bp      s1      s2      s3      s4      s5  \\\n",
      "0    0.0381  0.0507  0.0617  0.0219 -0.0442 -0.0348 -0.0434 -0.0026  0.0199   \n",
      "1   -0.0019 -0.0446 -0.0515 -0.0263 -0.0084 -0.0192  0.0744 -0.0395 -0.0683   \n",
      "2    0.0853  0.0507  0.0445 -0.0057 -0.0456 -0.0342 -0.0324 -0.0026  0.0029   \n",
      "3   -0.0891 -0.0446 -0.0116 -0.0367  0.0122  0.0250 -0.0360  0.0343  0.0227   \n",
      "4    0.0054 -0.0446 -0.0364  0.0219  0.0039  0.0156  0.0081 -0.0026 -0.0320   \n",
      "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "437  0.0417  0.0507  0.0197  0.0597 -0.0057 -0.0026 -0.0287 -0.0026  0.0312   \n",
      "438 -0.0055  0.0507 -0.0159 -0.0676  0.0493  0.0792 -0.0287  0.0343 -0.0181   \n",
      "439  0.0417  0.0507 -0.0159  0.0173 -0.0373 -0.0138 -0.0250 -0.0111 -0.0469   \n",
      "440 -0.0455 -0.0446  0.0391  0.0012  0.0163  0.0153 -0.0287  0.0266  0.0445   \n",
      "441 -0.0455 -0.0446 -0.0730 -0.0814  0.0837  0.0278  0.1738 -0.0395 -0.0042   \n",
      "\n",
      "         s6  \n",
      "0   -0.0176  \n",
      "1   -0.0922  \n",
      "2   -0.0259  \n",
      "3   -0.0094  \n",
      "4   -0.0466  \n",
      "..      ...  \n",
      "437  0.0072  \n",
      "438  0.0445  \n",
      "439  0.0155  \n",
      "440 -0.0259  \n",
      "441  0.0031  \n",
      "\n",
      "[442 rows x 10 columns]\n",
      "0     151.0000\n",
      "1      75.0000\n",
      "2     141.0000\n",
      "3     206.0000\n",
      "4     135.0000\n",
      "        ...   \n",
      "437   178.0000\n",
      "438   104.0000\n",
      "439   132.0000\n",
      "440   220.0000\n",
      "441    57.0000\n",
      "Name: target, Length: 442, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X2, y2 = load_diabetes(return_X_y=True, as_frame=True)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, random_state=0)\n",
    "print(X2, y2, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacking_regressor_mape 0.3294355656302654\n",
      "[248.19759057 240.42764024 177.37191492 103.86233455 200.13250024\n",
      " 250.97352765  96.82048975 220.71264013 131.5200259  236.41159677\n",
      " 175.71519802 160.35569454 130.9100711   93.65232358 282.06237765\n",
      "  99.93621948 161.47206754  78.65895059 108.86806694 224.46260151\n",
      " 182.68564834 127.54111953 163.28785267 138.89063619 220.53939703\n",
      " 189.84079506 136.98136758  78.91556812 219.66245835 159.14526636\n",
      " 198.39205847  82.77579781 117.59833274 157.49622357 139.53979064\n",
      " 171.05953707 152.42297469 135.62774138  94.81503188 213.49660018\n",
      " 110.36059875 162.00479518 132.07261264 178.57636808 179.29614901\n",
      "  73.3945309  114.601665   131.93470279 100.32309962 252.57462411\n",
      " 146.00870076  61.92053404 170.56742259 157.92964414 243.28628037\n",
      " 205.27588938 180.79716523 114.89480581 120.80464762 172.87785542\n",
      " 243.4033502  151.64437003 130.09006375 100.99049563 249.91693845\n",
      " 153.00241663  87.45729779 230.20145421 215.78130712  90.82440238\n",
      "  88.24276622 143.91478174 110.89538069 134.84971688 130.50875598\n",
      " 177.97770535 121.87554552 221.70653117 261.76922106 197.7323525\n",
      " 125.88596841 191.96118205  71.8331337  240.12385544 129.00872186\n",
      "  89.92647528 151.49862554 202.71572059 105.9398957  150.37365076\n",
      " 103.92670222 108.23845662  87.0924303  168.01234827 106.55530568\n",
      "  93.81879887 232.8935379  238.29278058 136.22349466 154.71341867\n",
      " 157.80577109 114.83038143 159.25202218 100.13701043 236.14776543\n",
      " 143.92620712 235.19141566 269.14119287 113.39076553  86.51606237\n",
      " 251.53999411]\n",
      "\n",
      "sk_stacking_regressor_mape 0.3294355656302654\n",
      "[248.19759057 240.42764024 177.37191492 103.86233455 200.13250024\n",
      " 250.97352765  96.82048975 220.71264013 131.5200259  236.41159677\n",
      " 175.71519802 160.35569454 130.9100711   93.65232358 282.06237765\n",
      "  99.93621948 161.47206754  78.65895059 108.86806694 224.46260151\n",
      " 182.68564834 127.54111953 163.28785267 138.89063619 220.53939703\n",
      " 189.84079506 136.98136758  78.91556812 219.66245835 159.14526636\n",
      " 198.39205847  82.77579781 117.59833274 157.49622357 139.53979064\n",
      " 171.05953707 152.42297469 135.62774138  94.81503188 213.49660018\n",
      " 110.36059875 162.00479518 132.07261264 178.57636808 179.29614901\n",
      "  73.3945309  114.601665   131.93470279 100.32309962 252.57462411\n",
      " 146.00870076  61.92053404 170.56742259 157.92964414 243.28628037\n",
      " 205.27588938 180.79716523 114.89480581 120.80464762 172.87785542\n",
      " 243.4033502  151.64437003 130.09006375 100.99049563 249.91693845\n",
      " 153.00241663  87.45729779 230.20145421 215.78130712  90.82440238\n",
      "  88.24276622 143.91478174 110.89538069 134.84971688 130.50875598\n",
      " 177.97770535 121.87554552 221.70653117 261.76922106 197.7323525\n",
      " 125.88596841 191.96118205  71.8331337  240.12385544 129.00872186\n",
      "  89.92647528 151.49862554 202.71572059 105.9398957  150.37365076\n",
      " 103.92670222 108.23845662  87.0924303  168.01234827 106.55530568\n",
      "  93.81879887 232.8935379  238.29278058 136.22349466 154.71341867\n",
      " 157.80577109 114.83038143 159.25202218 100.13701043 236.14776543\n",
      " 143.92620712 235.19141566 269.14119287 113.39076553  86.51606237\n",
      " 251.53999411]\n"
     ]
    }
   ],
   "source": [
    "reg_estimators = [RandomForestRegressor(random_state=0),\n",
    "                  GradientBoostingRegressor(random_state=0)]\n",
    "\n",
    "stacking_reg = Stacking(estimators=reg_estimators, final_estimator=RidgeCV())\n",
    "stacking_reg_pred_res = stacking_reg.fit_predict(X2_train, y2_train, X2_test)\n",
    "stacking_mape = mean_absolute_percentage_error(stacking_reg_pred_res, y2_test)\n",
    "print(f'stacking_regressor_mape {stacking_mape}')\n",
    "print(stacking_reg_pred_res, '', sep='\\n')\n",
    "\n",
    "sk_reg_estimators = [('rfr', RandomForestRegressor(random_state=0)),\n",
    "                     ('gbr', GradientBoostingRegressor(random_state=0))]\n",
    "\n",
    "sk_stacking_reg = StackingRegressor(estimators=sk_reg_estimators)\n",
    "sk_stacking_reg.fit(X2_train, y2_train)\n",
    "sk_stacking_reg_pred_res = sk_stacking_reg.predict(X2_test)\n",
    "sk_stacking_mape = mean_absolute_percentage_error(sk_stacking_reg_pred_res, y2_test)\n",
    "print(f'sk_stacking_regressor_mape {sk_stacking_mape}')\n",
    "print(sk_stacking_reg_pred_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
